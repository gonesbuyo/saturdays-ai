{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NLP Fundamentals with Python\n",
    "\n",
    "### Gonzalo Estrán Buyo, *Economics & AI Research.* \n",
    "Twitter: @__[sigmoider](https://twitter.com/sigmoider)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OUTLINE:\n",
    "\n",
    "### 1. Introducción\n",
    "### 2. Areas principales\n",
    "### 3. Arquitectura\n",
    "### 4. Hands-on\n",
    "### 5. State of the art\n",
    "### 6. Aplicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. INTRODUCCIÓN\n",
    "## *Qué <span style=\"color:red\">(NO)</span> es NLP*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **QUÉ NO ES NLP:**\n",
    "    - Neuro-Linguistic Programming\n",
    "    - Magia\n",
    "    - La solución para todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*GBCgmit0r4HkTR-92PizQw.jpeg\" align=\"right\">\n",
    "\n",
    "- **QUÉ ES NLP:**\n",
    "    - Natural Language Processing\n",
    "    - Un área de la IA: Lingüística + CS (ML)\n",
    "    - Características:\n",
    "        * Ambigüedad\n",
    "        * Sinonimia\n",
    "        * Sintaxis\n",
    "        * Correferencias / anáforas\n",
    "        * Normalización vs información\n",
    "        * Representación\n",
    "        * Personalidad / intención / estilo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ejemplo de coreferencia:*\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/0*d6NfdzNYB5tFZKi-.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. AREAS PRINCIPALES\n",
    "\n",
    "## *Principales retos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 1. Estemizado y lematización \n",
    "\n",
    "Reducción de diferentes variantes de una palabra a una sola forma básica.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/0*yTnH6cyfOK9oL-0D.png\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. Resolución de correferencias\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/94157dbf6ab835f0608aa44d8fca92b4ae74eeec/68747470733a2f2f68756767696e67666163652e636f2f636f7265662f6173736574732f7468756d626e61696c2d6c617267652e706e67\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3. Part-of-speech (POS) Tagging\n",
    "\n",
    "Etiquetar cada palabra de un corpus asignándole una categoría sintáctica que puede ser: \n",
    "* **abierta**: nombre, verbo, adjetivo, adverbio.\n",
    "* **cerrada**: preposición, determinante, pronombre, conjunción, verbo auxiliar, partícula, numeral.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*fRjvBbgzo90x0MZdXZT82A.png\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4. Dependency parsing\n",
    "\n",
    "Obtiene las dependencias o relaciones entre palabras como un árbol. Las dependencias consideradas son generalmente relaciones de **sujeto, objeto, complemento y modificador**.\n",
    " \n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*y7FVJfgBYOG6p2Je84FVXg.png\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5. Named Entity Recognition (NER)\n",
    "\n",
    "Trata de clasificar en categorías predefinidas (persona, lugar, tiempo, cantidad, etc.) las entidades de un un texto.\n",
    " \n",
    "<img src=\"https://www.depends-on-the-definition.com/wp-content/uploads/2018/12/namedentityextraction-945x468.png\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 6. Topic Modeling\n",
    "\n",
    "Agrupa las palabras más representativas del corpus en temáticas o materias.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/0*3YiGp_YuwcwPNfM8.png\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 7. Otros problemas de NLP\n",
    "\n",
    "- Sentiment Analysis\n",
    "- Natural Language Generation (NLG)\n",
    "- Question Answering\n",
    "- Text summarization\n",
    "- Relation extraction\n",
    "- Error Correction (grammatical, syntactic, spelling)\n",
    "- Machine Transalation\n",
    " \n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/0*lUAhiA6FDazmoDUx.gif\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. ARQUITECTURA\n",
    "## *Juntando las piezas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Cuatro fases principales:\n",
    "**1.** *Preprocesamiento del corpus:* preparación.\n",
    "\n",
    "**2.** *Estructuración:* identificación.\n",
    "\n",
    "**3.** *Análisis:* extracción.\n",
    "\n",
    "**4.** *Transformación:* ejecución de la decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1200/1*OgD8_FmQFBJ_cKst_H3WWw.jpeg\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. HANDS-ON\n",
    "## *Caso práctico*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Datos:\n",
    "\n",
    "__[Medium Articles](https://www.kaggle.com/hsankesara/medium-articles)__: una colección de 338 artículos sobre ML, AI, y Data Science extraídos de Medium (3,9 MB).\n",
    "\n",
    "### Dependencias:\n",
    "\n",
    "- __[Pandas](https://pandas.pydata.org)__: tratamiento de datos (se asume que ya está instalado).\n",
    "- __[SpaCy](https://spacy.io)__: modelos de NLP.\n",
    "- __[re](https://docs.python.org/3/library/re.html)__: expresiones regulares (viene por defecto).\n",
    "\n",
    "<img src=\"https://pandas.pydata.org/_static/pandas_logo.png\" width=\"250\" align=\"left\"> \n",
    "<br clear=\"all\" />\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/SpaCy_logo.svg/2000px-SpaCy_logo.svg.png\" width=\"150\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Para instalar SpaCy con Conda y el módulo de NLP en inglés:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Para instalar SpaCy con Conda y el módulo de NLP en inglés:\n",
    "\n",
    "!conda install -c conda-forge spacy\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Para instalarlo usando pip:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Para instalar SpaCy con Conda y el módulo de NLP en inglés:\n",
    "\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en') # cargamos módulo de inglés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Cargamos el corpus:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8.3K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>If you’ve ever found yourself looking up the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2.8K</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>Machine learning is increasingly moving from h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gant Laborde</td>\n",
       "      <td>1.3K</td>\n",
       "      <td>7</td>\n",
       "      <td>https://medium.freecodecamp.org/machine-learni...</td>\n",
       "      <td>Machine Learning: how to go from Zero to Hero ...</td>\n",
       "      <td>If your understanding of A.I. and Machine Lear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author claps  reading_time  \\\n",
       "0        Justin Lee  8.3K            11   \n",
       "1       Conor Dewey  1.4K             7   \n",
       "2  William Koehrsen  2.8K            11   \n",
       "3      Gant Laborde  1.3K             7   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1  https://towardsdatascience.com/python-for-data...   \n",
       "2  https://towardsdatascience.com/automated-featu...   \n",
       "3  https://medium.freecodecamp.org/machine-learni...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chatbots were the next big thing: what happene...   \n",
       "1  Python for Data Science: 8 Concepts You May Ha...   \n",
       "2  Automated Feature Engineering in Python – Towa...   \n",
       "3  Machine Learning: how to go from Zero to Hero ...   \n",
       "\n",
       "                                                text  \n",
       "0  Oh, how the headlines blared:\\nChatbots were T...  \n",
       "1  If you’ve ever found yourself looking up the s...  \n",
       "2  Machine learning is increasingly moving from h...  \n",
       "3  If your understanding of A.I. and Machine Lear...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/gonesbuyo/saturdays-ai/master/articles.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas (artículos): 337\n",
      "Columnas (campos): 6 \n",
      "\n",
      "['author', 'claps', 'reading_time', 'link', 'title', 'text'] \n",
      "\n",
      "AUTHOR: Justin Lee \n",
      "\n",
      "CLAPS: 8.3K \n",
      "\n",
      "READING_TIME: 11 \n",
      "\n",
      "LINK: https://medium.com/swlh/chatbots-were-the-next-big-thing-what-happened-5fc49dd6fa61?source=---------0---------------- \n",
      "\n",
      "TITLE: Chatbots were the next big thing: what happened? – The Startup – Medium \n",
      "\n",
      "TEXT: Oh, how the headlines blared:\n",
      "Chatbots were The Next Big Thing.\n",
      "Our hopes were sky high. Bright-eyed and bushy-tailed, the industry was ripe for a new era of innovation: it was time to start socializing with machines.\n",
      "And why wouldn’t they be? All the road signs pointed towards insane success.\n",
      "At the Mobile World Congress 2017, chatbots were the main headliners. The conference organizers cited an ‘overwhelming acceptance at the event of the inevitable shift of focus for brands and corporates to chatbots’.\n",
      "In fact, the only significant question around chatbots was who would monopolize the field, not whether chatbots would take off in the first place:\n",
      "One year on, we have an answer to that question.\n",
      "No.\n",
      "Because there isn’t even an ecosystem for a platform to dominate.\n",
      "Chatbots weren’t the first technological development to be talked up in grandiose terms and then slump spectacularly.\n",
      "The age-old hype cycle unfolded in familiar fashion...\n",
      "Expectations built, built, and then..... It all kind of fizzled out.\n",
      "The predicted paradim shift didn’t materialize.\n",
      "And apps are, tellingly, still alive and well.\n",
      "We look back at our breathless optimism and turn to each other, slightly baffled:\n",
      "“is that it? THAT was the chatbot revolution we were promised?”\n",
      "Digit’s Ethan Bloch sums up the general consensus:\n",
      "According to Dave Feldman, Vice President of Product Design at Heap, chatbots didn’t just take on one difficult problem and fail: they took on several and failed all of them.\n",
      "Bots can interface with users in different ways. The big divide is text vs. speech. In the beginning (of computer interfaces) was the (written) word.\n",
      "Users had to type commands manually into a machine to get anything done.\n",
      "Then, graphical user interfaces (GUIs) came along and saved the day. We became entranced by windows, mouse clicks, icons. And hey, we eventually got color, too!\n",
      "Meanwhile, a bunch of research scientists were busily developing natural language (NL) interfaces to databases, instead of having to learn an arcane database query language.\n",
      "Another bunch of scientists were developing speech-processing software so that you could just speak to your computer, rather than having to type. This turned out to be a whole lot more difficult than anyone originally realised:\n",
      "The next item on the agenda was holding a two-way dialog with a machine. Here’s an example dialog (dating back to the 1990s) with VCR setup system:\n",
      "Pretty cool, right? The system takes turns in collaborative way, and does a smart job of figuring out what the user wants.\n",
      "It was carefully crafted to deal with conversations involving VCRs, and could only operate within strict limitations.\n",
      "Modern day bots, whether they use typed or spoken input, have to face all these challenges, but also work in an efficient and scalable way on a variety of platforms.\n",
      "Basically, we’re still trying to achieve the same innovations we were 30 years ago.\n",
      "Here’s where I think we’re going wrong:\n",
      "An oversized assumption has been that apps are ‘over’, and would be replaced by bots.\n",
      "By pitting two such disparate concepts against one another (instead of seeing them as separate entities designed to serve different purposes) we discouraged bot development.\n",
      "You might remember a similar war cry when apps first came onto the scene ten years ago: but do you remember when apps replaced the internet?\n",
      "It’s said that a new product or service needs to be two of the following: better, cheaper, or faster. Are chatbots cheaper or faster than apps? No — not yet, at least.\n",
      "Whether they’re ‘better’ is subjective, but I think it’s fair to say that today’s best bot isn’t comparable to today’s best app.\n",
      "Plus, nobody thinks that using Lyft is too complicated, or that it’s too hard to order food or buy a dress on an app. What is too complicated is trying to complete these tasks with a bot — and having the bot fail.\n",
      "A great bot can be about as useful as an average app. When it comes to rich, sophisticated, multi-layered apps, there’s no competition.\n",
      "That’s because machines let us access vast and complex information systems, and the early graphical information systems were a revolutionary leap forward in helping us locate those systems.\n",
      "Modern-day apps benefit from decades of research and experimentation. Why would we throw this away?\n",
      "But, if we swap the word ‘replace’ with ‘extend’, things get much more interesting.\n",
      "Today’s most successful bot experiences take a hybrid approach, incorporating chat into a broader strategy that encompasses more traditional elements.\n",
      "The next wave will be multimodal apps, where you can say what you want (like with Siri) and get back information as a map, text, or even a spoken response.\n",
      "Another problematic aspect of the sweeping nature of hype is that it tends to bypass essential questions like these.\n",
      "For plenty of companies, bots just aren’t the right solution. The past two years are littered with cases of bots being blindly applied to problems where they aren’t needed.\n",
      "Building a bot for the sake of it, letting it loose and hoping for the best will never end well:\n",
      "The vast majority of bots are built using decision-tree logic, where the bot’s canned response relies on spotting specific keywords in the user input.\n",
      "The advantage of this approach is that it’s pretty easy to list all the cases that they are designed to cover. And that’s precisely their disadvantage, too.\n",
      "That’s because these bots are purely a reflection of the capability, fastidiousness and patience of the person who created them; and how many user needs and inputs they were able to anticipate.\n",
      "Problems arise when life refuses to fit into those boxes.\n",
      "According to recent reports, 70% of the 100,000+ bots on Facebook Messenger are failing to fulfil simple user requests. This is partly a result of developers failing to narrow their bot down to one strong area of focus.\n",
      "When we were building GrowthBot, we decided to make it specific to sales and marketers: not an ‘all-rounder’, despite the temptation to get overexcited about potential capabilties.\n",
      "Remember: a bot that does ONE thing well is infinitely more helpful than a bot that does multiple things poorly.\n",
      "A competent developer can build a basic bot in minutes — but one that can hold a conversation? That’s another story. Despite the constant hype around AI, we’re still a long way from achieving anything remotely human-like.\n",
      "In an ideal world, the technology known as NLP (natural language processing) should allow a chatbot to understand the messages it receives. But NLP is only just emerging from research labs and is very much in its infancy.\n",
      "Some platforms provide a bit of NLP, but even the best is at toddler-level capacity (for example, think about Siri understanding your words, but not their meaning.)\n",
      "As Matt Asay outlines, this results in another issue: failure to capture the attention and creativity of developers.\n",
      "And conversations are complex. They’re not linear. Topics spin around each other, take random turns, restart or abruptly finish.\n",
      "Today’s rule-based dialogue systems are too brittle to deal with this kind of unpredictability, and statistical approaches using machine learning are just as limited. The level of AI required for human-like conversation just isn’t available yet.\n",
      "And in the meantime, there are few high-quality examples of trailblazing bots to lead the way. As Dave Feldman remarked:\n",
      "Once upon a time, the only way to interact with computers was by typing arcane commands to the terminal. Visual interfaces using windows, icons or a mouse were a revolution in how we manipulate information\n",
      "There’s a reasons computing moved from text-based to graphical user interfaces (GUIs). On the input side, it’s easier and faster to click than it is to type.\n",
      "Tapping or selecting is obviously preferable to typing out a whole sentence, even with predictive (often error-prone ) text. On the output side, the old adage that a picture is worth a thousand words is usually true.\n",
      "We love optical displays of information because we are highly visual creatures. It’s no accident that kids love touch screens. The pioneers who dreamt up graphical interface were inspired by cognitive psychology, the study of how the brain deals with communication.\n",
      "Conversational UIs are meant to replicate the way humans prefer to communicate, but they end up requiring extra cognitive effort. Essentially, we’re swapping something simple for a more-complex alternative.\n",
      "Sure, there are some concepts that we can only express using language (“show me all the ways of getting to a museum that give me 2000 steps but don’t take longer than 35 minutes”), but most tasks can be carried out more efficiently and intuitively with GUIs than with a conversational UI.\n",
      "Aiming for a human dimension in business interactions makes sense.\n",
      "If there’s one thing that’s broken about sales and marketing, it’s the lack of humanity: brands hide behind ticket numbers, feedback forms, do-not-reply-emails, automated responses and gated ‘contact us’ forms.\n",
      "Facebook’s goal is that their bots should pass the so-called Turing Test, meaning you can’t tell whether you are talking to a bot or a human. But a bot isn’t the same as a human. It never will be.\n",
      "A conversation encompasses so much more than just text.\n",
      "Humans can read between the lines, leverage contextual information and understand double layers like sarcasm. Bots quickly forget what they’re talking about, meaning it’s a bit like conversing with someone who has little or no short-term memory.\n",
      "As HubSpot team pinpointed:\n",
      "People aren’t easily fooled, and pretending a bot is a human is guaranteed to diminish returns (not to mention the fact that you’re lying to your users).\n",
      "And even those rare bots that are powered by state-of-the-art NLP, and excel at processing and producing content, will fall short in comparison.\n",
      "And here’s the other thing. Conversational UIs are built to replicate the way humans prefer to communicate — with other humans.\n",
      "But is that how humans prefer to interact with machines?\n",
      "Not necessarily.\n",
      "At the end of the day, no amount of witty quips or human-like mannerisms will save a bot from conversational failure.\n",
      "In a way, those early-adopters weren’t entirely wrong.\n",
      "People are yelling at Google Home to play their favorite song, ordering pizza from the Domino’s bot and getting makeup tips from Sephora. But in terms of consumer response and developer involvement, chatbots haven’t lived up to the hype generated circa 2015/16.\n",
      "Not even close.\n",
      "Computers are good at being computers. Searching for data, crunching numbers, analyzing opinions and condensing that information.\n",
      "Computers aren’t good at understanding human emotion. The state of NLP means they still don’t ‘get’ what we’re asking them, never mind how we feel.\n",
      "That’s why it’s still impossible to imagine effective customer support, sales or marketing without the essential human touch: empathy and emotional intelligence.\n",
      "For now, bots can continue to help us with automated, repetitive, low-level tasks and queries; as cogs in a larger, more complex system. And we did them, and ourselves, a disservice by expecting so much, so soon.\n",
      "But that’s not the whole story.\n",
      "Yes, our industry massively overestimated the initial impact chatbots would have. Emphasis on initial.\n",
      "As Bill Gates once said:\n",
      "The hype is over. And that’s a good thing. Now, we can start examining the middle-grounded grey area, instead of the hyper-inflated, frantic black and white zone.\n",
      "I believe we’re at the very beginning of explosive growth. This sense of anti-climax is completely normal for transformational technology.\n",
      "Messaging will continue to gain traction. Chatbots aren’t going away. NLP and AI are becoming more sophisticated every day.\n",
      "Developers, apps and platforms will continue to experiment with, and heavily invest in, conversational marketing.\n",
      "And I can’t wait to see what happens next.\n",
      "From a quick cheer to a standing ovation, clap to show how much you enjoyed this story.\n",
      "Head of Growth for GrowthBot, Messaging & Conversational Strategy @HubSpot\n",
      "Medium's largest publication for makers. Subscribe to receive our top stories here → https://goo.gl/zHcLJi\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Filas (artículos):', list(df.shape)[0])\n",
    "print('Columnas (campos):', list(df.shape)[1], '\\n')\n",
    "\n",
    "campos = list(df.keys())\n",
    "print(campos, '\\n')\n",
    "\n",
    "for c in campos:\n",
    "    print(c.upper() +':', df[c][0], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Lemmatizing, POS tagging, dependencias, **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc = nlp(u'This is a sentence written in Spain that mentions Facebook and can be found at http://google.com')\n",
    "\n",
    "df_token = pd.DataFrame()\n",
    "\n",
    "for i, token in enumerate(doc):\n",
    "    df_token.loc[i, 'text'] = token.text\n",
    "    df_token.loc[i, 'lemma'] = token.lemma_,\n",
    "    df_token.loc[i, 'pos'] = token.pos_\n",
    "    df_token.loc[i, 'tag'] = token.tag_\n",
    "    df_token.loc[i, 'dep'] = token.dep_\n",
    "    df_token.loc[i, 'shape'] = token.shape_\n",
    "    df_token.loc[i, 'is_alpha'] = token.is_alpha\n",
    "    df_token.loc[i, 'is_stop'] = token.is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>dep</th>\n",
       "      <th>shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>(be,)</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>(a,)</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence</td>\n",
       "      <td>(sentence,)</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>written</td>\n",
       "      <td>(write,)</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>acl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>(in,)</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>(spain,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>pobj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>that</td>\n",
       "      <td>(that,)</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>WDT</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mentions</td>\n",
       "      <td>(mention,)</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>relcl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>(facebook,)</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>dobj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>(and,)</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>cc</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>can</td>\n",
       "      <td>(can,)</td>\n",
       "      <td>VERB</td>\n",
       "      <td>MD</td>\n",
       "      <td>aux</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>be</td>\n",
       "      <td>(be,)</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VB</td>\n",
       "      <td>auxpass</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>found</td>\n",
       "      <td>(find,)</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>ccomp</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>at</td>\n",
       "      <td>(at,)</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>http://google.com</td>\n",
       "      <td>(http://google.com,)</td>\n",
       "      <td>X</td>\n",
       "      <td>ADD</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx://xxxx.xxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 text                 lemma    pos  tag        dep  \\\n",
       "0                This                  this    DET   DT      nsubj   \n",
       "1                  is                 (be,)   VERB  VBZ       ROOT   \n",
       "2                   a                  (a,)    DET   DT        det   \n",
       "3            sentence           (sentence,)   NOUN   NN  nsubjpass   \n",
       "4             written              (write,)   VERB  VBN        acl   \n",
       "5                  in                 (in,)    ADP   IN       prep   \n",
       "6               Spain              (spain,)  PROPN  NNP       pobj   \n",
       "7                that               (that,)    ADJ  WDT      nsubj   \n",
       "8            mentions            (mention,)   VERB  VBZ      relcl   \n",
       "9            Facebook           (facebook,)  PROPN  NNP       dobj   \n",
       "10                and                (and,)  CCONJ   CC         cc   \n",
       "11                can                (can,)   VERB   MD        aux   \n",
       "12                 be                 (be,)   VERB   VB    auxpass   \n",
       "13              found               (find,)   VERB  VBN      ccomp   \n",
       "14                 at                 (at,)    ADP   IN       prep   \n",
       "15  http://google.com  (http://google.com,)      X  ADD       pobj   \n",
       "\n",
       "              shape is_alpha is_stop  \n",
       "0              Xxxx     True    True  \n",
       "1                xx     True    True  \n",
       "2                 x     True    True  \n",
       "3              xxxx     True   False  \n",
       "4              xxxx     True   False  \n",
       "5                xx     True    True  \n",
       "6             Xxxxx     True   False  \n",
       "7              xxxx     True    True  \n",
       "8              xxxx     True   False  \n",
       "9             Xxxxx     True   False  \n",
       "10              xxx     True    True  \n",
       "11              xxx     True    True  \n",
       "12               xx     True    True  \n",
       "13             xxxx     True   False  \n",
       "14               xx     True    True  \n",
       "15  xxxx://xxxx.xxx    False   False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Dependecy Parsing**\n",
    "\n",
    "[DisplaCy](https://explosion.ai/demos/displacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Expresiones regulares**\n",
    "\n",
    "Nos permiten 'matchear' secuencias de caracteres que cumplen condiciones concretas.\n",
    "\n",
    "Para aprender: __[RegEx101](https://regex101.com/)__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This ', 'is ', 'a ', 'sentence ', 'written ', 'in ', 'Spain ', 'that ', 'mentions ', 'Facebook ', 'and ', 'can ', 'be ', 'found ', 'at ', '[URL]']\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for w in doc:\n",
    "    word = w.string\n",
    "    word = re.sub(r'(^(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?)', '[URL]', word)\n",
    "    l.append(word)\n",
    "    \n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Puntuaciones y stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuations = ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. STATE OF THE ART\n",
    "## *Deep NLP*\n",
    "\n",
    "* RNNs / LSTMs\n",
    "* word2vec / GloVe / fastText\n",
    "* Reinforcement Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **6. APLICACIONES**\n",
    "## *Ontologías, chatbots y otros*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Ontologías**\n",
    "\n",
    "<img src=\"https://enterprise-knowledge.com/cms/assets/uploads/2017/02/Ontology_Design.png\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **Chatbots**\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*IS8nFJznvfsmLRLv-cKyDw.png\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **CÓMO EMPEZAR**\n",
    "\n",
    "* Estadística + ML: \n",
    "    * Cursos: Udacity, Coursera, Udemy.\n",
    "    * Artículos: Medium\n",
    "    * Libros: *Hands‑On Machine Learning with Scikit‑Learn and TensorFlow* (A. Géron), *Machine Learning* (Mitchell).\n",
    "    \n",
    "    \n",
    "* Papers:\n",
    "    * [paperswithcode](http://paperswithcode.com)\n",
    "    * [Must-Read NLP Papers](http://masatohagiwara.net/100-nlp-papers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **RECURSOS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
